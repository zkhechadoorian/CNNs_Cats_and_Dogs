{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/zkhechadoorian/CNNs_Cats_and_Dogs/research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/zkhechadoorian/CNNs_Cats_and_Dogs'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    training_data: Path\n",
    "    params_epochs: int\n",
    "    params_batch_size: int\n",
    "    params_is_augmentation: bool\n",
    "    params_image_size: list\n",
    "    scan_over_freeze_till_models_path: Path  # <-- Add this line\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PrepareCallbacksConfig:\n",
    "    root_dir: Path\n",
    "    tensorboard_root_log_dir: Path\n",
    "    checkpoint_model_filepath: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 00:51:37.539857: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-20 00:51:37.540350: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-20 00:51:37.608455: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-20 00:51:39.288644: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-20 00:51:39.289135: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "from ImageClassification.constants import *\n",
    "from ImageClassification.utils import read_yaml, create_directories\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    \n",
    "    def get_prepare_callback_config(self) -> PrepareCallbacksConfig:\n",
    "        config = self.config.prepare_callbacks\n",
    "        model_ckpt_dir = os.path.dirname(config.checkpoint_model_filepath)\n",
    "        create_directories([\n",
    "            Path(model_ckpt_dir),\n",
    "            Path(config.tensorboard_root_log_dir)\n",
    "        ])\n",
    "\n",
    "        prepare_callback_config = PrepareCallbacksConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            tensorboard_root_log_dir=Path(config.tensorboard_root_log_dir),\n",
    "            checkpoint_model_filepath=Path(config.checkpoint_model_filepath)\n",
    "        )\n",
    "\n",
    "        return prepare_callback_config\n",
    "    \n",
    "\n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        training = self.config.training\n",
    "        prepare_base_model = self.config.prepare_base_model\n",
    "        params = self.params\n",
    "        training_data = os.path.join(self.config.data_ingestion.unzip_dir, \"PetImages\")\n",
    "        create_directories([\n",
    "            Path(training.root_dir)\n",
    "        ])\n",
    "\n",
    "        training_config = TrainingConfig(\n",
    "            root_dir=Path(training.root_dir),\n",
    "            trained_model_path=Path(training.trained_model_path),\n",
    "            updated_base_model_path=Path(prepare_base_model.updated_base_model_path),\n",
    "            training_data=Path(training_data),\n",
    "            params_epochs=params.EPOCHS,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_is_augmentation=params.AUGMENTATION,\n",
    "            params_image_size=params.IMAGE_SIZE,\n",
    "            scan_over_freeze_till_models_path=Path(training.scan_over_freeze_till_models_path)\n",
    "        )\n",
    "\n",
    "        return training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareCallback:\n",
    "    def __init__(self, config: PrepareCallbacksConfig):\n",
    "        self.config = config\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def _create_tb_callbacks(self):\n",
    "        timestamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "        tb_running_log_dir = os.path.join(\n",
    "            self.config.tensorboard_root_log_dir,\n",
    "            f\"tb_logs_at_{timestamp}\",\n",
    "        )\n",
    "        return tf.keras.callbacks.TensorBoard(log_dir=tb_running_log_dir)\n",
    "    \n",
    "\n",
    "\n",
    "    @property\n",
    "    def _create_ckpt_callbacks(self):\n",
    "        return tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=str(self.config.checkpoint_model_filepath),  # Convert WindowsPath to string\n",
    "            save_best_only=True\n",
    "        )\n",
    "\n",
    "\n",
    "    def get_tb_ckpt_callbacks(self):\n",
    "        return [\n",
    "            self._create_tb_callbacks,\n",
    "            self._create_ckpt_callbacks\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def get_base_model(self):\n",
    "        self.model = tf.keras.models.load_model(\n",
    "            self.config.updated_base_model_path, compile=False\n",
    "        )\n",
    "        \n",
    "        self.model.compile(\n",
    "            optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), \n",
    "            loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "\n",
    "    def train_valid_generator(self):\n",
    "\n",
    "        datagenerator_kwargs = dict(\n",
    "            rescale = 1./255,\n",
    "            validation_split=0.20\n",
    "        )\n",
    "\n",
    "        dataflow_kwargs = dict(\n",
    "            target_size=self.config.params_image_size[:-1],\n",
    "            batch_size=self.config.params_batch_size,\n",
    "            interpolation=\"bilinear\"\n",
    "        )\n",
    "\n",
    "        valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            **datagenerator_kwargs\n",
    "        )\n",
    "\n",
    "        self.valid_generator = valid_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"validation\",\n",
    "            shuffle=False,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "        if self.config.params_is_augmentation:\n",
    "            train_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                rotation_range=40,\n",
    "                horizontal_flip=True,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                #brightness_range=[0.7, 1.3],         # Add brightness augmentation\n",
    "                #channel_shift_range=30.0,            # Add color shift\n",
    "                **datagenerator_kwargs\n",
    "            )\n",
    "        else:\n",
    "            train_datagenerator = valid_datagenerator\n",
    "\n",
    "        self.train_generator = train_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"training\",\n",
    "            shuffle=True,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model):\n",
    "        model.save(path)\n",
    "\n",
    "\n",
    "    def train(self, callback_list: list):\n",
    "        self.steps_per_epoch = self.train_generator.samples // self.train_generator.batch_size\n",
    "        self.validation_steps = self.valid_generator.samples // self.valid_generator.batch_size\n",
    "\n",
    "        history = self.model.fit(\n",
    "            self.train_generator,\n",
    "            epochs=self.config.params_epochs,\n",
    "            steps_per_epoch=self.steps_per_epoch,\n",
    "            validation_steps=self.validation_steps,\n",
    "            validation_data=self.valid_generator,\n",
    "            callbacks=callback_list\n",
    "        )\n",
    "\n",
    "        self.save_model(\n",
    "            path=self.config.trained_model_path,\n",
    "            model=self.model\n",
    "        )\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate extra augmented cat images and save them to a new folder\n",
    "os.system('rm artifacts/data_ingestion/PetImages/Cat/*aug*')\n",
    "os.system('rm artifacts/data_ingestion/PetImages/Dog/*aug*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.89_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.975_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.956_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.864_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.2446_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.869_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.2431_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.883_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.900_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.990_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.2417_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.966_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.985_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.983_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.2462_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.860_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.890_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.897_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.947_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.2441_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.917_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.872_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.2429_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.86_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.867_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.865_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.2445_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.951_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.898_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.2409_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.991_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.884_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.970_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.866_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.2440_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.893_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.878_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.919_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.870_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.2433_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.2456_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.875_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.2405_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.979_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.91_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.952_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.863_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.2426_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.907_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.2449_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.858_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.961_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.973_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.960_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.2415_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.913_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.959_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.902_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.2407_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.891_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.2448_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.987_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.988_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.87_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.996_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.886_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.967_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.911_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.997_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.980_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.905_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.2452_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.895_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.986_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.885_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.899_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.2453_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.995_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.982_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.2432_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.2419_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.877_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.889_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.94_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.92_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/2_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.2436_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.892_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.2425_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.914_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.977_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.2423_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.2424_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.904_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.879_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.874_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.2430_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.894_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.949_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Cat/cat.882_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.999_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.961_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.2450_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.941_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.847_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.2420_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.877_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.881_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.2421_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.2458_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.851_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.856_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.2445_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.2452_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.988_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.2454_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.865_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.973_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.87_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.883_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.848_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.2456_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.2415_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.991_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.2451_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.868_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.948_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.995_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.882_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.946_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.879_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.2461_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.2455_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.943_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.963_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.860_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.2457_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.871_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.863_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.992_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/10493_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.92_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.897_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.989_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.891_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.845_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.2443_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.2432_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.983_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.956_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.894_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.2428_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.2447_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.2442_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.2449_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.997_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.953_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.947_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.2438_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.867_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.976_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.858_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.2459_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.967_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.950_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.2406_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.2404_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.861_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.2417_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.2436_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.888_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.853_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.2446_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.958_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.990_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.969_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.2441_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.993_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.962_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.974_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.2460_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.2439_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.2407_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.960_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.873_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.870_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.874_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.876_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.971_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.96_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.893_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.981_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.2408_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.945_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.864_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.872_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.944_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.862_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.889_augmented.jpg\n",
      "Saved: artifacts/data_ingestion/PetImages/Dog/dog.898_augmented.jpg\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def augment_and_save_images(src_dir, n_images, augmented_datagen, prefix):\n",
    "    img_files = [f for f in os.listdir(src_dir) if f.lower().endswith(('jpg', 'jpeg', 'png'))][:n_images]\n",
    "    for fname in img_files:\n",
    "        img_path = os.path.join(src_dir, fname)\n",
    "        img = load_img(img_path, target_size=(224, 224))  # Resize to match model input size\n",
    "        x = img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        aug_iter = augmented_datagen.flow(x, batch_size=1)\n",
    "        aug_img = next(aug_iter)[0].astype(np.uint8)\n",
    "        # Build new filename\n",
    "        name, ext = os.path.splitext(fname)\n",
    "        aug_fname = f\"{name}_augmented{ext}\"\n",
    "        aug_path = os.path.join(src_dir, aug_fname)\n",
    "        array_to_img(aug_img).save(aug_path)\n",
    "        print(f\"Saved: {aug_path}\")\n",
    "\n",
    "# Augment and save 100 images for Cats\n",
    "augment_and_save_images(cat_source_dir, 100, augmented_datagen, prefix=\"cat\")\n",
    "\n",
    "# Augment and save 100 images for Dogs\n",
    "augment_and_save_images(dog_source_dir, 100, augmented_datagen, prefix=\"dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After running this, add augmented images to your training set directory.\n",
    "os.system('mv artifacts/data_ingestion/AugmentedImages/Cat/* artifacts/data_ingestion/PetImages/Cat/')\n",
    "os.system('mv artifacts/data_ingestion/AugmentedImages/Dog/* artifacts/data_ingestion/PetImages/Dog/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls artifacts/data_ingestion/PetImages/Cat/ | wc\n",
    "%ls artifacts/data_ingestion/PetImages/Dog/ | wc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "## Learning Curves: Accuracy and Loss vs. Epochs\n",
    "\n",
    "In the next cell, we will plot the learning curves for the training process, showing how the model's accuracy and loss evolve over the epochs for both the training and validation datasets.\n",
    "\n",
    "### Accuracy\n",
    "Accuracy is a metric that measures the proportion of correctly classified samples out of the total samples. It is calculated as:\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Predictions}}\n",
    "$$\n",
    "\n",
    "A higher accuracy indicates better model performance. The training accuracy shows how well the model performs on the training data, while the validation accuracy indicates its performance on unseen data.\n",
    "\n",
    "### Loss\n",
    "Loss is a measure of the error in the model's predictions. In this project, we use **categorical cross-entropy** as the loss function, which is commonly used for multi-class classification tasks.\n",
    "\n",
    "Categorical cross-entropy measures the difference between the true label distribution (one-hot encoded) and the predicted probability distribution from the model. It is calculated as:\n",
    "\n",
    "$$\n",
    "\\text{Loss} = -\\sum_{i=1}^{C} y_i \\log(p_i)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ y_i $ is the true label for class \\( i \\) (1 for the correct class, 0 for others)\n",
    "- $ p_i $ is the predicted probability for class \\( i \\)\n",
    "- $ C $ is the number of classes\n",
    "\n",
    "Lower loss values indicate better model performance. Similar to accuracy, we track both training loss and validation loss.\n",
    "\n",
    "### Interpreting the Graphs\n",
    "1. **Training Curves**: The training accuracy and loss curves show how well the model is learning from the training data. Ideally, the training accuracy should increase, and the training loss should decrease over epochs.\n",
    "2. **Validation Curves**: The validation accuracy and loss curves indicate how well the model generalizes to unseen data. Ideally, the validation accuracy should increase, and the validation loss should decrease. If the validation loss starts increasing while the validation accuracy plateaus or decreases, it may indicate overfitting.\n",
    "\n",
    "By analyzing these graphs, we can assess the model's learning behavior and identify potential issues such as underfitting or overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_training_curve import plot_training_curves\n",
    "\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prepare_callbacks_config = config.get_prepare_callback_config()\n",
    "    prepare_callbacks = PrepareCallback(config=prepare_callbacks_config)\n",
    "    callback_list = prepare_callbacks.get_tb_ckpt_callbacks()\n",
    "\n",
    "    training_config = config.get_training_config()\n",
    "    training = Training(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.train_valid_generator()\n",
    "    history = training.model.fit(\n",
    "        training.train_generator,\n",
    "        epochs=training.config.params_epochs,\n",
    "        #steps_per_epoch=training.steps_per_epoch,\n",
    "        #alidation_steps=training.validation_steps,\n",
    "        validation_data=training.valid_generator,\n",
    "        callbacks=callback_list\n",
    "    )\n",
    "\n",
    "    plot_training_curves(history)\n",
    "    \n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "## Epoch Selection: Stabilization of Loss\n",
    "\n",
    "Upon analyzing the loss vs. epochs curve, it is observed that the loss stabilizes around 10-12 epochs. This indicates that the model reaches a point of diminishing returns in terms of improvement in training and validation loss beyond this range. \n",
    "\n",
    "To balance training time and model performance, I have decided to use **12 epochs** for training. This choice ensures that the model is trained sufficiently while avoiding unnecessary computational overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning with Different Numbers of Trainable Layers\n",
    "\n",
    "In the next block of code, we perform **fine-tuning** of the model by iteratively unfreezing different numbers of layers in the pre-trained base model. This process involves the following steps:\n",
    "\n",
    "1. **Freeze Layers**: For each value of `freeze_till` (ranging from 0 to 10), the specified number of layers from the beginning of the model are frozen (i.e., their weights are not updated during training). The remaining layers are set to be trainable.\n",
    "\n",
    "2. **Re-Compilation**: After modifying the trainable status of the layers, the model is recompiled to ensure the changes take effect.\n",
    "\n",
    "3. **Training**: The model is trained using the training data and the specified callbacks. The training process adjusts the weights of the trainable layers to improve performance.\n",
    "\n",
    "4. **Saving the Model**: After training, the model is saved with a unique filename that includes the `freeze_till` value, allowing us to evaluate and compare the performance of models fine-tuned with different numbers of trainable layers.\n",
    "\n",
    "This approach helps identify the optimal number of layers to unfreeze for fine-tuning, balancing the benefits of leveraging pre-trained features and adapting the model to the specific dataset. The results will be analyzed in subsequent cells to determine the best configuration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prepare_callbacks_config = config.get_prepare_callback_config()\n",
    "    prepare_callbacks = PrepareCallback(config=prepare_callbacks_config)\n",
    "    callback_list = prepare_callbacks.get_tb_ckpt_callbacks()\n",
    "\n",
    "    training_config = config.get_training_config()\n",
    "    training = Training(config=training_config)\n",
    "    training.train_valid_generator()\n",
    "\n",
    "    # Loop over freeze_till values\n",
    "    for freeze_till in range(0, 11, 2):\n",
    "        print(f\"\\nTraining with freeze_till={freeze_till}\")\n",
    "        # Load and update the base model for each freeze_till value\n",
    "        training.get_base_model()  # Loads the base model\n",
    "        # Freeze layers: you need to add this logic to your Training class or do it here\n",
    "        for layer in training.model.layers[:-freeze_till] if freeze_till > 0 else []:\n",
    "            layer.trainable = False\n",
    "        for layer in training.model.layers[-freeze_till:] if freeze_till > 0 else training.model.layers:\n",
    "            layer.trainable = True\n",
    "        # Re-compile after changing trainable status\n",
    "        training.model.compile(\n",
    "            optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "            loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "        # Train the model\n",
    "        training.train(callback_list=callback_list)\n",
    "        # Save with a unique name\n",
    "        trained_model_path = str(training.config.trained_model_path).replace(\".h5\", f\"_augmented_freeze_{freeze_till}.h5\")\n",
    "        training.save_model(trained_model_path, training.model)\n",
    "        print(f\"Saved model: {trained_model_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Prepare to store results\n",
    "freeze_till_values = []\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "\n",
    "# Loop through your saved models\n",
    "for freeze_till in range(0, 11,2):\n",
    "    model_path = str(training.config.trained_model_path).replace(\".h5\", f\"_augmented_freeze_{freeze_till}.h5\")\n",
    "    print(f\"Evaluating model: {model_path}\")\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    # Evaluate on validation data\n",
    "    loss, acc = model.evaluate(training.valid_generator, verbose=0)\n",
    "    freeze_till_values.append(freeze_till)\n",
    "    val_accuracies.append(acc)\n",
    "    val_losses.append(loss)\n",
    "    print(f\"freeze_till={freeze_till}: val_accuracy={acc:.4f}\")\n",
    "\n",
    "# Plot accuracy vs Freeze_till\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(freeze_till_values, val_accuracies, marker='o')\n",
    "plt.xlabel('freeze_till')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.title('Validation Accuracy vs. No. of Re-trained Layers')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot loss vs Freeze_till\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(freeze_till_values, val_losses, marker='o')\n",
    "plt.xlabel('freeze_till')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.title('Validation Loss vs. No. of Re-trained Layers')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "## Final Decision: 12 Epochs and freeze_till=4\n",
    "\n",
    "After analyzing the results of fine-tuning with different numbers of trainable layers, it is evident that the optimal configuration is achieved with **freeze_till=4**. This choice is based on the following observations:\n",
    "\n",
    "1. **Accuracy**: The validation accuracy is maximized when 4 layers are re-trained, indicating the best generalization performance on unseen data.\n",
    "2. **Loss**: The validation loss is minimized at the same point, suggesting that the model achieves the lowest error in predictions.\n",
    "\n",
    "Additionally, the decision to use **12 epochs** is based on the stabilization of the loss curve observed earlier. This ensures that the model is trained sufficiently without overfitting or unnecessary computational overhead.\n",
    "\n",
    "By using **12 epochs** and **freeze_till=4**, we achieve a balance between training efficiency and model performance, making it the ideal configuration for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "tex"
    }
   },
   "source": [
    "\n",
    "## ROC and AUC Curves: Understanding and Interpretation\n",
    "\n",
    "### ROC Curve\n",
    "The **Receiver Operating Characteristic (ROC) curve** is a graphical representation of a classification model's performance across different threshold values. It plots the **True Positive Rate (TPR)** (also known as sensitivity or recall) against the **False Positive Rate (FPR)** at various threshold settings.\n",
    "\n",
    "- **True Positive Rate (TPR)**: The proportion of actual positives correctly identified by the model.\n",
    "    $$\n",
    "    TPR = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}\n",
    "    $$\n",
    "- **False Positive Rate (FPR)**: The proportion of actual negatives incorrectly classified as positives.\n",
    "    $$\n",
    "    FPR = \\frac{\\text{False Positives}}{\\text{False Positives} + \\text{True Negatives}}\n",
    "    $$\n",
    "\n",
    "The ROC curve provides a comprehensive view of the trade-off between sensitivity and specificity for a classifier.\n",
    "\n",
    "### AUC (Area Under the Curve)\n",
    "The **Area Under the Curve (AUC)** quantifies the overall ability of the model to discriminate between positive and negative classes. It is a single scalar value ranging from 0 to 1:\n",
    "- **AUC = 1**: Perfect classifier.\n",
    "- **AUC = 0.5**: Random guessing (no discrimination ability).\n",
    "- **AUC < 0.5**: Worse than random guessing.\n",
    "\n",
    "### Interpreting the ROC and AUC\n",
    "1. **Closer to the Top-Left Corner**: A good ROC curve is closer to the top-left corner, indicating high TPR and low FPR.\n",
    "2. **Higher AUC**: A higher AUC value indicates better model performance. For example:\n",
    "     - **AUC = 0.9**: Excellent model.\n",
    "     - **AUC = 0.7â€“0.8**: Acceptable model.\n",
    "     - **AUC < 0.7**: Poor model.\n",
    "\n",
    "### Practical Use\n",
    "The ROC curve and AUC are particularly useful for evaluating models in imbalanced datasets, where accuracy alone may not provide a complete picture of performance. By analyzing the ROC curve, you can select an optimal threshold that balances sensitivity and specificity based on the problem's requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training.valid_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plot_roc_curve import plot_roc_auc\n",
    "\n",
    "# use model with 12 epochs and freeze_till=6\n",
    "model = tf.keras.models.load_model(\n",
    "    str(training.config.trained_model_path).replace(\".h5\", f\"_augmented_freeze_4.h5\")\n",
    ")\n",
    "\n",
    "# set y_true and y_pred_proba\n",
    "y_true = training.valid_generator.classes\n",
    "y_pred_proba = model.predict(training.valid_generator) # contains probabilities for each class [cat, dog]\n",
    "\n",
    "# plot_roc_auc(y_true, y_pred_proba, n_classes=None)\n",
    "plot_roc_auc(y_true, y_pred_proba[:,1], n_classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
